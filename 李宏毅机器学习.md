# 课程简介

## introduction

机器学习的三个步骤：

1. 定义模型：定义带未知量的函数
2. 定义损失函数：
3. 优化：找参数最优值，如gradient descent

机器学习=找函数f()，大致分类

- 二分类：输出是与否
- 回归：输出标量
- 多分类：CNN输出分类

怎么告诉机器需要的函数：

- 监督学习：labeled data
  - 计算Loss
  - 机器会自动找出loss最低的情况
- 强化学习：alphaGo——监督学习之上强化学习
- 无监督学习

机器怎样找出你想要的函数？

## rule

- git
- github
- Ubuntu环境下pyenv配置



## gradient and error

### gradient：梯度下降法

### error来自：

- variance：方差造成的偏差，理解为预测值之间的偏差，训练集误差小，测试集大==过拟合
  - 解决：更多data；正则化——让曲线更加平滑
- bias：均值造成的偏差，理解为预测与真实值之间的偏差，训练集误差大==欠拟合
  - 

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20201027204600646.png" alt="image-20201027204600646" style="zoom:80%;" />

# 深度学习

## 简介

怎样提升准确度？

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309152535164.png" alt="image-20210309152535164" style="zoom: 67%;" />

- 过拟合：
  - 更多训练数据
  - 数据增强（翻转、裁剪）
  - 限制模型：减少参数、参数共享（CNN）、减少特征、提前结束、正则化、dropout
- 交叉验证：N-fold Cross Validation
- mismatch：训练集和测试集分布不一样

## 优化——梯度消失

- 梯度消失：当走到梯度为0的地方，训练几乎停止

  - 鞍点：微分为0的点，可解决

  - 局部最优：local minima/maxima，不可解决

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309145858695.png" alt="image-20210309145858695" style="zoom:67%;" />

- 判断方法：Hessian矩阵是二次微分矩阵

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210312155725425.png" alt="image-20210312155725425" style="zoom:80%;" />

  - 当我们抵达critical point即梯度为0的时候，绿色这一项为0，可以通过红色部分来判断当前是局部最优还是鞍点

  - 很简单，我们可以分三种情况，如图很直观地指出了分类方法：每种类别的第二行是等价条件，可以通过特征值来判断是否正定

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210312160339857.png" alt="image-20210312160339857" style="zoom:80%;" />

  - 通过鞍点的特征向量来计算loss减小的方向（实作中几乎没人这么做）

  

- 从经验上看：鞍点更常见

## 优化——训练提示

### batch

为什么要用batch

- 实验表明，batch_size越大，精确度会下降。一种可能的解释是batch训练时的loss函数不一样，因而遇到鞍点时可以继续训练

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309153907587.png" alt="image-20210309153907587" style="zoom:67%;" />

- 实验表明，小批量测试集表现也更好（泛化性）

- 劣势：batch_size越大，每一epoc用时越大，总用时越少

### momentum

- 类比物理中的动量、惯性，每一次梯度更新方向还要考虑前一次梯度方向

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309155155708.png" alt="image-20210309155155708" style="zoom:80%;" />

### Adaptive Learning Rate

- 怎样选择学习率？？

- 原则：梯度变化平缓，学习率设置大一点；反之，小一点

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316100705186.png" alt="image-20210316100705186" style="zoom:80%;" />

- Adagrad方法：

  - 更新原则：
    $$
    \boldsymbol{\theta}_{i}^{t+1} \leftarrow \boldsymbol{\theta}_{i}^{t}-\frac{\eta}{\sigma_{i}^{t}} \boldsymbol{g}_{i}^{t} \quad \sigma_{i}^{t}=\sqrt{\frac{1}{t+1} \sum_{i=0}^{t}\left(\boldsymbol{g}_{i}^{t}\right)^{2}}
    $$

  - 其中，g为梯度，$\eta$为学习率

  - 直观解释：缓梯度的时候，参数更小，学习率就更大

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316101446560.png" alt="image-20210316101446560" style="zoom:50%;" />

  - 缺点：参数不随时间变化，不能动态调整

- RMSProp：

  - 思路：可以自己调整梯度的占比
    $$
    \begin{aligned}
    &\boldsymbol{\theta}_{i}^{1} \leftarrow \boldsymbol{\theta}_{i}^{0}-\frac{\eta}{\sigma_{i}^{0}} g_{i}^{0} \quad \sigma_{i}^{0}=\sqrt{\left(g_{i}^{0}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{2} \leftarrow \boldsymbol{\theta}_{i}^{1}-\frac{\eta}{\sigma_{i}^{1}} g_{i}^{1} \quad \sigma_{i}^{1}=\sqrt{\alpha\left(\sigma_{i}^{0}\right)^{2}+(1-\alpha)\left(g_{i}^{1}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{3} \leftarrow \boldsymbol{\theta}_{i}^{2}-\frac{\eta}{\sigma_{i}^{2}} g_{i}^{2} \quad \sigma_{i}^{2}=\sqrt{\alpha\left(\sigma_{i}^{1}\right)^{2}+(1-\alpha)\left(g_{i}^{2}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{t+1} \leftarrow \boldsymbol{\theta}_{i}^{t}-\frac{\eta}{\sigma_{i}^{t}} \boldsymbol{g}_{i}^{t} \quad \sigma_{i}^{t}=\sqrt{\alpha\left(\sigma_{i}^{t-1}\right)^{2}+(1-\alpha)\left(\boldsymbol{g}_{\mathfrak{q}}^{t}\right)^{2}}
    \end{aligned}
    $$


- Adam：RMSProp+Momentum
- 学习率衰减decay
- warm up：学习率先增后减（resNet、Transformer）

### 优化总结

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316103252293.png" alt="image-20210316103252293" style="zoom: 50%;" />

## 分类（短版本）

- 用回归做：引入独热向量，每个类是一次回归

- 用分类区别：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316103847177.png" alt="image-20210316103847177" style="zoom:67%;" />

- Loss函数：基本都用Cross-entropy交叉熵，MSE也可以但是hui

- PS：pytorch里面，如果使用nn.CrossEntropyLoss() 则自动使用softmax而不需要添加softmax层



# CNN & Self-Attention

## CNN

- 背景：输入大小一样，输出为one-hot

- 已有的解决方法：将图片像素全部拉直成特征，喂到DNN中

- 观察1：通过找图中的patterns（我理解为：部分特征），然后进行提取

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316145529979.png" alt="image-20210316145529979" style="zoom:67%;" />

  所以得到简化方法：分receptive field考虑，比如先考虑任意3x3x3

  引入基本概念：kernel size、channel、stride、padding、

- 观察2：同一个patterns可能出现在不同图片的不同地方

  简化方法：共享参数（filter相同）

- 卷积层：

  - 使用filter来抓取图像中的patterns

  - 图像通过filter得到的结果叫：feature map

  - 有多少filter，feature map就有多少channels

  - 多层卷积层的效果：如下图，假设上面矩阵（原图）用3x3卷积核，然后得到下面矩阵，如果再来一次卷积，则卷积的范围在原图中就更大一点（蓝色框）。也就是层越深，考虑的范围越大

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316153948211.png" alt="image-20210316153948211" style="zoom:50%;" />

- 观察3：

  - 下采样subsampling：即缩小图片，比如可以间隔s个像素取出来生成新的图片

- 整个框架

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316155023358.png" alt="image-20210316155023358" style="zoom:67%;" />

- 应用：下围棋

## self-attention

### intro

- 前面看到的输入都一样长，那么如果输入不一样长的序列会怎么办呢
  - 举例：输入序列this is a cat
    - 表示方法——独热向量：一个词占一个维度，但没有突出单词间的关系
    - word embedding：每个词一个向量（包含语义），同类词进行聚类【一句话就是长度不一的向量】
  - 举例：音频、图结构（社交网络）、分子结构
- 输出情况：
  - 一个向量对应一个label【sequence labeling】：如POS tagging（标词性）、声音识别（HW2）、社交网络图
  - 所有向量对应一个label：Sentiment analysis（情感分析）、语音辨认、判断分子是什么
  - 模型决定输出长度：【seq2seq】（HW5）

### 自注意力

https://www.youtube.com/watch?v=hYdO9CscNes

#### 先前做法

考虑输入输出一样的情况【sequence labeling】

- 先前做法：分别对每一个sequence进行FC，独立判断这个sequence的输出

- 但是sequence之间是有联系的，因此得考虑context

- 因此当前FC可以给当前和前后向量，如下图

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210326152046725.png" alt="image-20210326152046725" style="zoom:67%;" />

  问题：输入序列长度不一致，全面概括需要大量参数

#### 引入自注意力

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151209129.png" alt="image-20210318151209129" style="zoom:67%;" />

- self-attention可交替/叠加使用（多次使用）

- 内部结构

  - a1~a4可能时输入层，也可能是隐藏层

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151415172.png" alt="image-20210318151415172" style="zoom:67%;" />

  - 那么怎么考虑b1与a1相关的向量之间得关联性呢?

- 评估相关程度$\alpha$的方法：

  - $\alpha$代表  

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151807291.png" alt="image-20210318151807291" style="zoom:67%;" />

- 具体做法：

  - 计算a1与a2~a4之间的关联性

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151949157.png" alt="image-20210318151949157" style="zoom:67%;" />

  - 一般自己跟自己也计算关联性（可实验）

  - 使用softmax进行normalization
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318152052851.png" alt="image-20210318152052851" style="zoom:67%;" />
  
  - 基于attention分数抽取重要资讯：attention分数越大，在最终信息中占比就越大
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318152339780.png" alt="image-20210318152339780" style="zoom:67%;" />
  
  ​	
  

# Theory of ML



















# Transformer

## Normalization

### Batch Normalization训练部分

HW3（CNN）能用上

- 问题：当不同特征的input值时大时小，导致权重w对于损失函数的变化也时大时小

  怎么将输入放在同一个范围中呢

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330145852476.png" alt="image-20210330145852476" style="zoom:67%;" />

- 方法：Feature Normalization 

  将同一维度，不同特征的变量标准化【标准化】

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330150249812.png" alt="image-20210330150249812" style="zoom:67%;" />

- 细节：Normalization放在激活函数前后都可

- 引入BN：引入均值和方差（都是向量），参数也更多，一般是一次batch算一次，也叫batch normalization

### 测试部分

- 使用moving average来计算均值和方差，pytorch中自动计算

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330151521760.png" alt="image-20210330151521760" style="zoom:67%;" />

- 为什么BN有用？

  看paper，貌似是一个偶然的发现2333333



## Transformer

### 简介

- Seq2seq模型：模型决定输出长度
- 应用：

  - 语音识别【语音转文字】
  - 机器翻译【文字转文字】
  - 语音翻译【语音另一种文字】（因为有些语言没有文字）
  - 语音合成【文字转语音】
  - 聊天机器人【input->seq2seq->reply】
  - QA【question & context->seq2seq->answer】
  - 文法剖析【硬 train 一發 】论文：Grammar as a foreign language
  - multi-lable classification【自己决定label数】
  - 目标检测【https://arxiv.org/abs/2005.12872】
- seq2seq起源：https://arxiv.org/abs/1409.3215

### encoder

- encoder部分==bert的结构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210416173444271.png" alt="image-20210416173444271" style="zoom:67%;" />

  - 结构变化相关论文：
    - https://arxiv.org/abs/2002.04745  【On Layer Normalization in the Transformer Architecture】
    - https://arxiv.org/abs/2003.07845 【PowerNorm: Rethinking Batch Normalization in Transformers】

### decoder

- decoder架构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418162535707.png" alt="image-20210418162535707" style="zoom:67%;" />

  首先，给decoder一个Begin Of Sentences(自己设计的独热向量)，然后通过decoder输出序列向量，再经过softmax，选出可能性最大的预测值，并将输出作为下一次的输入

- 结构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165505367.png" alt="image-20210418165505367" style="zoom:67%;" />

- masked self-attention：做attention时只考虑前面的序列，如下图生成b2时之关注a1和a2

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165425721.png" alt="image-20210418165425721" style="zoom:67%;" />

- 怎么让他停止产生序列？

  设置end标识符

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165816847.png" alt="image-20210418165816847" style="zoom:67%;" />

- AT(autogressive) vs NAT：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418170104702.png" alt="image-20210418170104702" style="zoom:67%;" />

  - NAT优势：并行性、可控输出长度、但通常比AT表现差

- 传递部分：cross attention

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418170555481.png" alt="image-20210418170555481" style="zoom:67%;" />

  - 关于cross attention不一定要从encoder的最后一层来融合的论文：https://arxiv.org/abs/2005.08081



### 训练

- 损失函数：最小化cross entropy

- teacher forcing：将真实值当作decoder输入

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418172011357.png" alt="image-20210418172011357" style="zoom:67%;" />



### tips

- 复制机制：

  - 聊天机器人（对于不懂得东西，直接复制）、总结

  - 进一步了解↓

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418172313805.png" alt="image-20210418172313805" style="zoom: 50%;" />

- guided attention：强迫学习到相关的样貌【monotonic attention、location-aware attention】

- beam search

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418173244744.png" alt="image-20210418173244744" style="zoom:67%;" />

- 原文训练时用BLUE score衡量而不是cross entropy，BLUE越大越好，衡量句子之间的距离。但BLUE不可微分，不能求导，用强化学习硬train吧

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418173927797.png" alt="image-20210418173927797" style="zoom:67%;" />

- exposure bias：面临一步错步步错的问题，怎么办？

  在训练的时候就加一些错误信息

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418174056060.png" alt="image-20210418174056060" style="zoom:67%;" />

  解决：scheduled sampling

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418174132556.png" alt="image-20210418174132556" style="zoom:67%;" />

# xxx































































































