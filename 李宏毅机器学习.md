[toc]



# 课程简介

## introduction

机器学习的三个步骤：

1. 定义模型：定义带未知量的函数
2. 定义损失函数：
3. 优化：找参数最优值，如gradient descent

机器学习=找函数f()，大致分类

- 二分类：输出是与否
- 回归：输出标量
- 多分类：CNN输出分类

怎么告诉机器需要的函数：

- 监督学习：labeled data
  - 计算Loss
  - 机器会自动找出loss最低的情况
- 强化学习：alphaGo——监督学习之上强化学习
- 无监督学习

机器怎样找出你想要的函数？

## rule

- git
- github
- Ubuntu环境下pyenv配置



## gradient and error

### gradient：梯度下降法

### error来自：

- variance：方差造成的偏差，理解为预测值之间的偏差，训练集误差小，测试集大==过拟合
  - 解决：更多data；正则化——让曲线更加平滑
- bias：均值造成的偏差，理解为预测与真实值之间的偏差，训练集误差大==欠拟合
  - 

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20201027204600646.png" alt="image-20201027204600646" style="zoom:80%;" />

# 深度学习

## 简介

怎样提升准确度？

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309152535164.png" alt="image-20210309152535164" style="zoom: 67%;" />

- 过拟合：
  - 更多训练数据
  - 数据增强（翻转、裁剪）
  - 限制模型：减少参数、参数共享（CNN）、减少特征、提前结束、正则化、dropout
- 交叉验证：N-fold Cross Validation
- mismatch：训练集和测试集分布不一样

## 优化——梯度消失

- 梯度消失：当走到梯度为0的地方，训练几乎停止

  - 鞍点：微分为0的点，可解决

  - 局部最优：local minima/maxima，不可解决

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309145858695.png" alt="image-20210309145858695" style="zoom:67%;" />

- 判断方法：Hessian矩阵是二次微分矩阵

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210312155725425.png" alt="image-20210312155725425" style="zoom:80%;" />

  - 当我们抵达critical point即梯度为0的时候，绿色这一项为0，可以通过红色部分来判断当前是局部最优还是鞍点

  - 很简单，我们可以分三种情况，如图很直观地指出了分类方法：每种类别的第二行是等价条件，可以通过特征值来判断是否正定

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210312160339857.png" alt="image-20210312160339857" style="zoom:80%;" />

  - 通过鞍点的特征向量来计算loss减小的方向（实作中几乎没人这么做）

  

- 从经验上看：鞍点更常见

## 优化——训练提示

### batch

为什么要用batch

- 实验表明，batch_size越大，精确度会下降。一种可能的解释是batch训练时的loss函数不一样，因而遇到鞍点时可以继续训练

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309153907587.png" alt="image-20210309153907587" style="zoom:67%;" />

- 实验表明，小批量测试集表现也更好（泛化性）

- 劣势：batch_size越大，每一epoc用时越大，总用时越少

### momentum

- 类比物理中的动量、惯性，每一次梯度更新方向还要考虑前一次梯度方向

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210309155155708.png" alt="image-20210309155155708" style="zoom:80%;" />

### Adaptive Learning Rate

- 怎样选择学习率？？

- 原则：梯度变化平缓，学习率设置大一点；反之，小一点

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316100705186.png" alt="image-20210316100705186" style="zoom:80%;" />

- Adagrad方法：

  - 更新原则：
    $$
    \boldsymbol{\theta}_{i}^{t+1} \leftarrow \boldsymbol{\theta}_{i}^{t}-\frac{\eta}{\sigma_{i}^{t}} \boldsymbol{g}_{i}^{t} \quad \sigma_{i}^{t}=\sqrt{\frac{1}{t+1} \sum_{i=0}^{t}\left(\boldsymbol{g}_{i}^{t}\right)^{2}}
    $$

  - 其中，g为梯度，$\eta$为学习率

  - 直观解释：缓梯度的时候，参数更小，学习率就更大

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316101446560.png" alt="image-20210316101446560" style="zoom:50%;" />

  - 缺点：参数不随时间变化，不能动态调整

- RMSProp：

  - 思路：可以自己调整梯度的占比
    $$
    \begin{aligned}
    &\boldsymbol{\theta}_{i}^{1} \leftarrow \boldsymbol{\theta}_{i}^{0}-\frac{\eta}{\sigma_{i}^{0}} g_{i}^{0} \quad \sigma_{i}^{0}=\sqrt{\left(g_{i}^{0}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{2} \leftarrow \boldsymbol{\theta}_{i}^{1}-\frac{\eta}{\sigma_{i}^{1}} g_{i}^{1} \quad \sigma_{i}^{1}=\sqrt{\alpha\left(\sigma_{i}^{0}\right)^{2}+(1-\alpha)\left(g_{i}^{1}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{3} \leftarrow \boldsymbol{\theta}_{i}^{2}-\frac{\eta}{\sigma_{i}^{2}} g_{i}^{2} \quad \sigma_{i}^{2}=\sqrt{\alpha\left(\sigma_{i}^{1}\right)^{2}+(1-\alpha)\left(g_{i}^{2}\right)^{2}}\\
    &\boldsymbol{\theta}_{i}^{t+1} \leftarrow \boldsymbol{\theta}_{i}^{t}-\frac{\eta}{\sigma_{i}^{t}} \boldsymbol{g}_{i}^{t} \quad \sigma_{i}^{t}=\sqrt{\alpha\left(\sigma_{i}^{t-1}\right)^{2}+(1-\alpha)\left(\boldsymbol{g}_{\mathfrak{q}}^{t}\right)^{2}}
    \end{aligned}
    $$


- Adam：RMSProp+Momentum
- 学习率衰减decay
- warm up：学习率先增后减（resNet、Transformer）

### 优化总结

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316103252293.png" alt="image-20210316103252293" style="zoom: 50%;" />

## 分类（短版本）

- 用回归做：引入独热向量，每个类是一次回归

- 用分类区别：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316103847177.png" alt="image-20210316103847177" style="zoom:67%;" />

- Loss函数：基本都用Cross-entropy交叉熵，MSE也可以但是hui

- PS：pytorch里面，如果使用nn.CrossEntropyLoss() 则自动使用softmax而不需要添加softmax层



# CNN & Self-Attention

## CNN

- 背景：输入大小一样，输出为one-hot

- 已有的解决方法：将图片像素全部拉直成特征，喂到DNN中

- 观察1：通过找图中的patterns（我理解为：部分特征），然后进行提取

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316145529979.png" alt="image-20210316145529979" style="zoom:67%;" />

  所以得到简化方法：分receptive field考虑，比如先考虑任意3x3x3

  引入基本概念：kernel size、channel、stride、padding、

- 观察2：同一个patterns可能出现在不同图片的不同地方

  简化方法：共享参数（filter相同）

- 卷积层：

  - 使用filter来抓取图像中的patterns

  - 图像通过filter得到的结果叫：feature map

  - 有多少filter，feature map就有多少channels

  - 多层卷积层的效果：如下图，假设上面矩阵（原图）用3x3卷积核，然后得到下面矩阵，如果再来一次卷积，则卷积的范围在原图中就更大一点（蓝色框）。也就是层越深，考虑的范围越大

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316153948211.png" alt="image-20210316153948211" style="zoom:50%;" />

- 观察3：

  - 下采样subsampling：即缩小图片，比如可以间隔s个像素取出来生成新的图片

- 整个框架

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210316155023358.png" alt="image-20210316155023358" style="zoom:67%;" />

- 应用：下围棋

## self-attention

### intro

- 前面看到的输入都一样长，那么如果输入不一样长的序列会怎么办呢
  - 举例：输入序列this is a cat
    - 表示方法——独热向量：一个词占一个维度，但没有突出单词间的关系
    - word embedding：每个词一个向量（包含语义），同类词进行聚类【一句话就是长度不一的向量】
  - 举例：音频、图结构（社交网络）、分子结构
- 输出情况：
  - 一个向量对应一个label【sequence labeling】：如POS tagging（标词性）、声音识别（HW2）、社交网络图
  - 所有向量对应一个label：Sentiment analysis（情感分析）、语音辨认、判断分子是什么
  - 模型决定输出长度：【seq2seq】（HW5）

### 自注意力

https://www.youtube.com/watch?v=hYdO9CscNes

#### 先前做法

考虑输入输出一样的情况【sequence labeling】

- 先前做法：分别对每一个sequence进行FC，独立判断这个sequence的输出

- 但是sequence之间是有联系的，因此得考虑context

- 因此当前FC可以给当前和前后向量，如下图

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210326152046725.png" alt="image-20210326152046725" style="zoom:67%;" />

  问题：输入序列长度不一致，全面概括需要大量参数

#### 引入自注意力

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151209129.png" alt="image-20210318151209129" style="zoom:67%;" />

- self-attention可交替/叠加使用（多次使用）

- 内部结构

  - a1~a4可能时输入层，也可能是隐藏层

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151415172.png" alt="image-20210318151415172" style="zoom:67%;" />

  - 那么怎么考虑b1与a1相关的向量之间得关联性呢?

- 评估相关程度$\alpha$的方法：

  - $\alpha$代表  

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151807291.png" alt="image-20210318151807291" style="zoom:67%;" />

- 具体做法：

  - 计算a1与a2~a4之间的关联性

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318151949157.png" alt="image-20210318151949157" style="zoom:67%;" />

  - 一般自己跟自己也计算关联性（可实验）

  - 使用softmax进行normalization
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318152052851.png" alt="image-20210318152052851" style="zoom:67%;" />
  
  - 基于attention分数抽取重要资讯：attention分数越大，在最终信息中占比就越大
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210318152339780.png" alt="image-20210318152339780" style="zoom:67%;" />
  
  ​	

# Theory of ML



















# Transformer

## Normalization

### Batch Normalization训练部分

HW3（CNN）能用上

- 问题：当不同特征的input值时大时小，导致权重w对于损失函数的变化也时大时小

  怎么将输入放在同一个范围中呢

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330145852476.png" alt="image-20210330145852476" style="zoom:67%;" />

- 方法：Feature Normalization 

  将同一维度，不同特征的变量标准化【标准化】

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330150249812.png" alt="image-20210330150249812" style="zoom:67%;" />

- 细节：Normalization放在激活函数前后都可

- 引入BN：引入均值和方差（都是向量），参数也更多，一般是一次batch算一次，也叫batch normalization

### 测试部分

- 使用moving average来计算均值和方差，pytorch中自动计算

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210330151521760.png" alt="image-20210330151521760" style="zoom:67%;" />

- 为什么BN有用？

  看paper，貌似是一个偶然的发现2333333



## Transformer

### 简介

- Seq2seq模型：模型决定输出长度
- 应用：

  - 语音识别【语音转文字】
  - 机器翻译【文字转文字】
  - 语音翻译【语音另一种文字】（因为有些语言没有文字）
  - 语音合成【文字转语音】
  - 聊天机器人【input->seq2seq->reply】
  - QA【question & context->seq2seq->answer】
  - 文法剖析【硬 train 一發 】论文：Grammar as a foreign language
  - multi-lable classification【自己决定label数】
  - 目标检测【https://arxiv.org/abs/2005.12872】
- seq2seq起源：https://arxiv.org/abs/1409.3215

### encoder

- encoder部分==bert的结构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210416173444271.png" alt="image-20210416173444271" style="zoom:67%;" />

  - 结构变化相关论文：
    - https://arxiv.org/abs/2002.04745  【On Layer Normalization in the Transformer Architecture】
    - https://arxiv.org/abs/2003.07845 【PowerNorm: Rethinking Batch Normalization in Transformers】

### decoder

- decoder架构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418162535707.png" alt="image-20210418162535707" style="zoom:67%;" />

  首先，给decoder一个Begin Of Sentences(自己设计的独热向量)，然后通过decoder输出序列向量，再经过softmax，选出可能性最大的预测值，并将输出作为下一次的输入

- 结构：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165505367.png" alt="image-20210418165505367" style="zoom:67%;" />

- masked self-attention：做attention时只考虑前面的序列，如下图生成b2时之关注a1和a2

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165425721.png" alt="image-20210418165425721" style="zoom:67%;" />

- 怎么让他停止产生序列？

  设置end标识符

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418165816847.png" alt="image-20210418165816847" style="zoom:67%;" />

- AT(autogressive) vs NAT：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418170104702.png" alt="image-20210418170104702" style="zoom:67%;" />

  - NAT优势：并行性、可控输出长度、但通常比AT表现差

- 传递部分：cross attention

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418170555481.png" alt="image-20210418170555481" style="zoom:67%;" />

  - 关于cross attention不一定要从encoder的最后一层来融合的论文：https://arxiv.org/abs/2005.08081



### 训练

- 损失函数：最小化cross entropy

- teacher forcing：将真实值当作decoder输入

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418172011357.png" alt="image-20210418172011357" style="zoom:67%;" />



### tips

- 复制机制：

  - 聊天机器人（对于不懂得东西，直接复制）、总结

  - 进一步了解↓

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418172313805.png" alt="image-20210418172313805" style="zoom: 50%;" />

- guided attention：强迫学习到相关的样貌【monotonic attention、location-aware attention】

- beam search

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418173244744.png" alt="image-20210418173244744" style="zoom:67%;" />

- 原文训练时用BLUE score衡量而不是cross entropy，BLUE越大越好，衡量句子之间的距离。但BLUE不可微分，不能求导，用强化学习硬train吧

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418173927797.png" alt="image-20210418173927797" style="zoom:67%;" />

- exposure bias：面临一步错步步错的问题，怎么办？

  在训练的时候就加一些错误信息

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418174056060.png" alt="image-20210418174056060" style="zoom:67%;" />

  解决：scheduled sampling

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210418174132556.png" alt="image-20210418174132556" style="zoom:67%;" />

# GAN

## 基础

- 将网络作为生成器，输入x和z，z取自一个简单的分布（高斯分布等等），而y也就是一个分布

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421165116091.png" alt="image-20210421165116091" style="zoom:67%;" />

- 为什么需要输出一个分布？

  例子：视频预测糖豆人游戏的后面的画面时，如果用普通网络输入糖豆人有的向左有的向右，则他会预测一个糖豆人向左右转都对

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421165723286.png" alt="image-20210421165723286" style="zoom:67%;" />

  输出如果是分布，则可以预测概率

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421165851367.png" alt="image-20210421165851367" style="zoom:67%;" />

- 什么时候用：当人物需要有创造力的时候（同一个输入有多种正确的输出）

  - 画图【红眼睛：辉夜、库拉皮卡】
  - 聊天机器人【辉夜是谁：火影前传、猎人后传】

- 生成式模型中的GAN——以生成动漫人脸距离【unconditional generation：先把x拿掉】

  - 输入的z是一个低维向量，输出y是一个高维向量（图片）

  - generator的作用：想办法让简单的分布对应到高维向量

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421170658678.png" alt="image-20210421170658678" style="zoom:67%;" />

  - Discriminator：是一个神经网络（比如CNN），输入图片，输出标量值，代表图片的真实性

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421170910325.png" alt="image-20210421170910325" style="zoom:67%;" />

  - GAN基本思想：

    - 尝试用generator来骗过discriminator的检测，因此adversarial的意思就是他们俩是对抗关系，比如generator做假钞，discriminator是警察，则双方都会在竞争对抗中越来越厉害

      <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421171651651.png" alt="image-20210421171651651" style="zoom:67%;" />

- 算法：首先初始化Generator、Discriminator

  - step1：G固定，更新D。其中D可以使用回归或者分类来学习到真实数据与生成数据之间的差异

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421172245752.png" alt="image-20210421172245752" style="zoom:67%;" />

  - step2：固定D，训练G。相当于让D当作评价标准，训练G的准确率越高越好。网络将黄框部分合并，中间图片也当作一个hidden layer

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421172809053.png" alt="image-20210421172809053" style="zoom:67%;" />

  - 以上步骤反复训练

- 现有应用：

  - progressive GAN：生成现实人脸
  - style GAN：生成二次元人脸https://www.gwern.net/Faces
  - BigGAN


## 理论

### 简单理论

- 以一维分布举例，PG代表生成的分布，Pdata代表真实数据，Divergence代表PG和Pdata之间的某种距离

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421213553242.png" alt="image-20210421213553242" style="zoom:67%;" />

- 怎么计算divergence：做sample即可，图库、生成器分别取样

- discriminator：Pdata给高分，PG给低分。然后训练discriminator获得高分即可。目标函数V如下图

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210421221545311.png" alt="image-20210421221545311" style="zoom:67%;" />
  
  转换一下，之际上要求G\*等价于求D\*.那么就把D\*中的max替换过去就得到了：
  
  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422150246957.png" alt="image-20210422150246957" style="zoom:67%;" />

### tips——WGAN

- 问题：PG和Pdata重叠部分很少【因为都是sample出来的，不知道原来的样本重叠情况】

  当两个分布没有重合时，JS divergence==log2，所以容易产生无差别的差异

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422151804599.png" alt="image-20210422151804599" style="zoom:67%;" />

- Wasserstein distance用来计算从P分布到Q分布的平均最小步骤，如上图

  WGAN就是用W distance来计算PG和Pdata的距离而不用JS divergence。公式如下图，其中D需要足够平滑，X应该是Y代表输出

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422152302248.png" alt="image-20210422152302248" style="zoom:67%;" />

  其中，如果Pdata和PG无重叠，那么上式会让第一个Dx趋于无穷，第二个Dx区域负无穷，则无法收敛。因此需要D足够平滑

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422152447577.png" alt="image-20210422152447577" style="zoom:67%;" />

  - 设置上下界±c（原文）
  - 梯度惩罚（https://arxiv.org/abs/1704.00028）
  - SNGAN（https://arxiv.org/abs/1802.05957）

## 生成器效能評估與條件式生成

- GAN的问题：G和D容易同时退步，需要*棋逢敌手*

- 最难的是生成一段文字，G生成文字，D来判断生成文字与真实文字的差距。因为没法算微分：当改变decoder中的参数，最后max输出的值也不变，因此对于D来说没有改变

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422154956514.png" alt="image-20210422154956514" style="zoom:67%;" />

  虽然可用强化学习解决，但强化学习也很难训练

- 直到ScrachGAN（https://arxiv.org/abs/1905.09922）

- 选修内容：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422155316232.png" alt="image-20210422155316232" style="zoom:50%;" /><img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422155331319.png" alt="image-20210422155331319" style="zoom:50%;" />

-  可能的解决方法：随机的向量通过监督学习硬训练

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422155928340.png" alt="image-20210422155928340" style="zoom:67%;" />

  参考：https://arxiv.org/abs/1707.05776

  https://arxiv.org/abs/2007.02798

- 怎样评估生成图像的好坏？

  - 将图片放到图片分类器中，出来的分类结果越集中越好

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422160508163.png" alt="image-20210422160508163" style="zoom:67%;" />

  - 多样性：越平坦越好

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422161205431.png" alt="image-20210422161205431" style="zoom:67%;" />

  - IS的评价标准：质量高（单个有突出）且多样性大（总的平坦）

  - FID评价标准：图片经过cnn得到的向量（不经过softmax）之间的距离

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422161931130.png" alt="image-20210422161931130" style="zoom:67%;" />

- 存在的问题

  - mode collapse：训练时可能生成数据只围绕某一个真实数据，导致生成的图片反反复复就那几张

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422160743237.png" alt="image-20210422160743237" style="zoom:67%;" />

    解决：碰到问题之前停止训练，取上一次的model

  - model dropping（更难侦测出来）：训练时可能生成数据只围绕某些真实数据，比如下图第t次生成都是白脸，t+1次都是黄脸

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422160957357.png" alt="image-20210422160957357" style="zoom:67%;" />

- 另一个问题：可能G生成的图片和真实图片一模一样，那做GAN的目的是什么呢

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210422171112211.png" alt="image-20210422171112211" style="zoom:67%;" />

##  conditional GAN

加入条件x，从z中选取样本，得到y分布是有条件的GAN

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210424172112068.png" alt="image-20210424172112068" style="zoom:67%;" />

- 那么网络结构就需要调整：对于discriminator，评价时不光需要看生成图片是否真实，还要看与输入条件x是否匹配。对应的，标签也需要成对出现。

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210424172720756.png" alt="image-20210424172720756" style="zoom:67%;" />

- 不光是通过文字产生图片，还可以通过图片产生图片（黑白变彩色，素描变实物，去雾等等pix2pix应用）

  - 如果用监督学习，可能非常模糊

  - 因此可以用GAN+监督学习（https://arxiv.org/abs/1611.07004）

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210424173112520.png" alt="image-20210424173112520" style="zoom:67%;" />

- 莫名其妙的应用：

  - 声音->图像

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210424173306104.png" alt="image-20210424173306104" style="zoom:67%;" />

  - 图片变动图（https://arxiv.org/abs/1905.08233）

## Cycle GAN

- 无监督学习：样本无法获得labels【比如图片风格转换：将真实人物图片转成二次元风格】

- 面临的问题：如果使用下图所示的方法，D学习到的只是能让G生成二次元图片，但跟输入却没有关系。

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425170250536.png" alt="image-20210425170250536" style="zoom:67%;" />

- Cycle GAN：再增加一个G来保证输出与原图尽可能像

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425171247571.png" alt="image-20210425171247571" style="zoom:67%;" />

  理论上会出现G学到其他转换，比如左右翻转，但实作上，区别不大

- 双向Cycle GAN：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425171554356.png" alt="image-20210425171554356" style="zoom:67%;" />

- 其他GAN（前三个想法一致）

  - Disco GAN：https://arxiv.org/abs/1703.05192
  - Dual GAN：https://arxiv.org/abs/1704.02510
  - Cycle GAN：https://arxiv.org/abs/1703.10593
  - StarGAN：https://arxiv.org/abs/1711.09020
  - demo：http://selfie2anime.com/

- 文本风格转换：消极->积极

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425172148679.png" alt="image-20210425172148679" style="zoom:67%;" />

  - 其他应用：
    - 生成总结句子：https://arxiv.org/abs/1810.02851
    - 非监督翻译：https://arxiv.org/abs/1710.04087、https://arxiv.org/abs/11041
    - 分监督语音辨识：https://arxiv.org/abs/1804.00316、https://arxiv.org/abs/1812.09323、https://arxiv.org/abs/1904.04100



# 自监督学习

## 简介

- 芝麻街大家族（xswl233333也是自监督学习的家族

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425204148286.png" alt="image-20210425204148286" style="zoom: 50%;" />

- 模型参数越来越多......除了下图，还有GPT-3、switch transformer

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210425205040915.png" alt="image-20210425205040915" style="zoom:50%;" />



## BERT简介

- 自监督vs无监督：
  - 自监督是自己做label；
  
  - 无监督是无label
  
  - 自监督是一种无监督的方法
  
  - 比如下面这样，x分成两部分：$x^{'}$和$x^{''}$，前者用于训练，后者用于生成label
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426155345732.png" alt="image-20210426155345732" style="zoom:50%;" />
  
- masking input：将输入以随机概率进行mask（盖住）或者random替换成另一个字

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426160707409.png" alt="image-20210426160707409" style="zoom:67%;" />

- next sentence prediction：训练**[CLS]**用来表示句子是否关联（sentence 1和sentence 2是否连接），但这个方法可能不是很适用

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426161213448.png" alt="image-20210426161213448" style="zoom:67%;" />

- BERT学到：怎么去填空，可以来做各式各样的下游任务（微调）。【HW7】

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426191844194.png" alt="image-20210426191844194" style="zoom:67%;" />

- 评价标准：[GLUE](https://gluebenchmark.com/)，中文版本是[CLUE](https://cluebenchmarks.com/)。GLUE的分数等于9类任务的平均分

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426192608975.png" alt="image-20210426192608975" style="zoom:67%;" />

- BERT的使用例子1：输入序列输出分类【情感分析】，其中bert部分参数是pre-train的，Linear+softmax是随机初始化的，整体结构如下图，这个整体需要拿来进行半监督训练。

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426193002439.png" alt="image-20210426193002439" style="zoom:67%;" />

  https://arxiv.org/abs/1908.05620证明了预训练比随机初始化效果好

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426193158475.png" alt="image-20210426193158475" style="zoom:67%;" />

- BERT的使用例子2：输入输出都是序列，长度一样【词性标注】

- BERT的使用例子3：输入两个序列，输出类别【自然语言推理：吃两个句子，推断出其意见是赞同还是反对】

- BERT的使用例子4：Extraction-based QA【HW7】输出是两个整数s和e，代表第s到第e个词汇之间的就是答案

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426200251921.png" alt="image-20210426200251921" style="zoom:67%;" />

-  BERT输入的长度不是无限长，输入长了可以切割了再放入

- 做seq2seq需要对encoder的输入做corrupt（翻转、删除、顺序打乱等等），decoder的输出要训练得与输入一致

## BERT原理

- 因为BERT==encoder，所以这两边输入的果会根据attention考虑上下文信息，得到的embeddings向量也就不一样，计算其cos相似性

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426210304600.png" alt="image-20210426210304600" style="zoom:67%;" />

- 因此可以认为BERT输出的向量就代表那个字的意思，那么挖空可以直观解释为：利用上下文判断这个单词应该是什么（填空）

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426210800442.png" style="zoom:67%;" />

- 选修课：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426211404023.png" alt="image-20210426211404023" style="zoom:33%;" />

- Multi-lingual BERT：多语言训练的BERT，会做104种语言的填空题。

  实验中发现，英文训练QA，他能做中文QA

  其中pre-train代表会做填空题的训练

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426211715064.png" alt="image-20210426211715064" style="zoom:67%;" />

- 有趣的现象：如果分别用中文英文训练BERT，然后再计算他们的平均之间的差异，然后在一个英文任务中加上这个差异就能变成中文的任务

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210426213140462.png" alt="image-20210426213140462" style="zoom:67%;" />

  这样就可以做无监督的翻译啦

## GPT-3

回顾：Bert是做填空题，gpt是做预测后文的模型【生成的能力】icon：独角兽

- 基本结构：做masked-attention，然后预测下一个单词是什么

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506104256839.png" alt="image-20210506104256839" style="zoom: 67%;" />

- in-context learning：给任务描述和少许例子，预测出答案

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506105728380.png" alt="image-20210506105728380" style="zoom:67%;" />

- 选修：

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506105922818.png" alt="image-20210506105922818" style="zoom:33%;" />

- 拓展内容：半监督学习的应用总结，在各领域都有应用

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506110126950.png" alt="image-20210506110126950" style="zoom:67%;" />

  - SimCLR【https://arxiv.org/abs/2002.05709】：图像视觉表示
  - BYOL【https://arxiv.org/abs/2006.07733】：一种自我监督学习的新方法

## Auto-Encoders

回归：自监督学习也叫pre-train，不需要label data，比如bert可以做填空，gpt可以补全句子，做一些微调就可以把他们用在一些下游任务

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506111412516.png" alt="image-20210506111412516" style="zoom:67%;" />

- Auto-encoder（reconstruction）：根Cycle GAN差不多，将图片通过encoder转换成11维向量【叫embedding或者code或者】，然后向量通过decoder转换成另一张图片，要尽可能decoder生成的图像与原图接近

  也就是将高维向量转换成中间低维向量，然后再通过dimention reduction将低维向量转换成新的照片

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506152423892.png" alt="image-20210506152423892" style="zoom:67%;" />
  
- 选修：PCA等dimention reduction技术

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506152548518.png" alt="image-20210506152548518" style="zoom:33%;" />

- 为什么能用auto-encoder？

  一种解释是原来的图片特征无论怎么变换都只有很少几种或者几十种，那么我们就可以通过encoder化繁为简

- de-noising auto-encoder【https://dl.acm.org/doi/10.1145/1390156.1390294】：图片送入encoder之前添加噪声

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506153601073.png" alt="image-20210506153601073" style="zoom:67%;" />

- BERT也可以看作是一个de-noising auto-encoder

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506153901903.png" alt="image-20210506153901903" style="zoom:67%;" />

## auto-encoder的其他应用

- 在cv、nlp、语音处理领域都可以用auto-encoder

- Feature Disentangle特征解读：中间特征的每一个维度的含义是什么，比如对于语音来说：前50维代表背景信息，后50维代表说话者的信息

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506154337814.png" alt="image-20210506154337814" style="zoom:67%;" />
  
  - 应用：voice conversion音色变换（柯南变声器
  
    将中间向量提取的语音内容特征部分不变，讲话人的特征进行替换，就可以用别人的声音做音色转换
  
    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506161158597.png" alt="image-20210506161158597" style="zoom:67%;" />
  
- Discrete Latent Representation：将中间向量变成二分类形式，或者独热向量（强制让它学会）【即将中间向量变成离散的，且中间变量是自己学会的】

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210506214657219.png" alt="image-20210506214657219" style="zoom:67%;" />

  - VQVAE：学习一个Codebook让decoder从中选与encoder输出向量相似度最高的向量，codebook中向量个数固定。用于语音则codebook可以学到基本的音标

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507150902646.png" alt="image-20210507150902646" style="zoom:67%;" />

  - 文本表示：给一堆文本，让网络自己学会文本总结，但是可能他的总结是只有自己看得懂的，因此引入GAN中的discriminator来让中间变量更接近人写的文字【Cycle GAN】

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507151343453.png" alt="image-20210507151343453" style="zoom:67%;" />

- 更多应用：

  - 将auto-encoder中的decoder拿出来当Generator用

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507151651643.png" alt="image-20210507151651643" style="zoom:67%;" />

  - 压缩和解压缩（会失真

  - Anomaly Detection异常检测：判断新来的数据与原数据是否相似（normal or anomaly）

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507152115058.png" alt="image-20210507152115058" style="zoom:67%;" />

    可以用来做欺诈检测，比如信用卡交易、网络侵入检测、癌症癌细胞检测（是二分类问题吗？不太能是，因为一般训练集都有大量正常资料而很少有异常资料，因此这也叫one class）

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507152337617.png" alt="image-20210507152337617" style="zoom:67%;" />

    做法：训练正常照片，测试异常照片时，发现输出和输入差异较大，则判断为anomaly

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507152707163.png" alt="image-20210507152707163" style="zoom:67%;" />

  - 选修：

    <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210507152735179.png" alt="image-20210507152735179" style="zoom:50%;" />

  

  

  





 

























# 可解释AI/对抗攻击









# Domain Adaptation

## 简介

- domain shift问题：训练和测试集的分布不同【比如黑白数字识别，在彩色数字图上效果并不好】

- domain adaptive：类似迁移学习，将在A训练集训练的模型用在B场景

- 分类：

  - 输入分布不一样【:star:】
  - 输出分布不一样【比如：训练集每个数字出现的概率相同，而测试集某些数字出现概率大】
  - 输入输出关系不一样

  <img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607212712004.png" alt="image-20210607212712004" style="zoom:67%;" />

  这里只关注第一种情况



## 基本思想

情况：

- 当target domain量很足，且有标注时，可以直接拿来训练
- 当target domain量很少，且有标注时，可以用来微调source domain上的模型【类似bert】当心过拟合
- 当target domain量很足，且无标注时【:star:】

基本做法：训练一个网络，去掉差异（比如颜色信息），从而抽取出同样分布的特征

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607214340388.png" alt="image-20210607214340388" style="zoom:67%;" />

Domain Adversarial Training：

- domain classifier是一个二元分类器，类似GAN中的discriminator

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607215353480.png" alt="image-20210607215353480" style="zoom:67%;" />



优化1：预测结果越集中越好

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607215901782.png" alt="image-20210607215901782" style="zoom:67%;" />

优化2：如何解决训练测试集有不同的label的问题

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607220327372.png" alt="image-20210607220327372" style="zoom:67%;" />

进一步：如果测试集为空，使用Domain Generalization

- 情况1：训练集多个domain，学习模型间差异
- 情况2：测试集多个domain，类似数据增强来做

<img src="https://yumytest.oss-cn-chengdu.aliyuncs.com/img/image-20210607220824914.png" alt="image-20210607220824914" style="zoom:67%;" />







# Privacy v.s. ML

# RL



# Quantum ML





# Life-Long/Compression





# Meta Learning































